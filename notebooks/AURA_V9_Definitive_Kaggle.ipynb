{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AURA V11 CERBERUS - \"NEMESIS\" Protocol (Adversarial)\n",
                "\n",
                "**Objective**: Decouple Toxicity from Negative Sentiment.\n",
                "**Method**: Adversarial Training with Gradient Reversal Layer (GRL).\n",
                "\n",
                "### The Logic\n",
                "- **The Problem**: V10 learned that \"Negative Sentiment\" = \"Toxic\".\n",
                "- **The Fix**: We introduce an **Adversary Head** that tries to guess if a sample comes from the *Toxicity Dataset* (Source 0) or the *Sentiment Dataset* (Source 1).\n",
                "- **The Trick (GRL)**: When the Adversary tries to learn, we **flip the gradient**. \n",
                "    - If BERT extracts features that make it easy to tell Sentiment from Toxicity, it gets **punished**.\n",
                "    - BERT is forced to learn features that are \"Domain Invariant\" (true toxicity, not just sadness).\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: Imports & Setup\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
                "from torch.optim.lr_scheduler import OneCycleLR\n",
                "from transformers import BertModel, BertTokenizer\n",
                "from tqdm.notebook import tqdm\n",
                "from sklearn.metrics import f1_score\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "SEED = 42\n",
                "torch.manual_seed(SEED)\n",
                "np.random.seed(SEED)\n",
                "torch.backends.cudnn.deterministic = True\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Device: {device}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: Configuration V11 (NEMESIS)\n",
                "CONFIG = {\n",
                "    'encoder': 'bert-base-uncased',\n",
                "    'max_length': 128,\n",
                "    'num_emotion_classes': 7,\n",
                "    'dropout': 0.5,\n",
                "    'weight_decay': 0.1,\n",
                "    'batch_size': 32,\n",
                "    'gradient_accumulation': 2,\n",
                "    'epochs': 5,\n",
                "    'lr_bert': 2e-5,\n",
                "    'lr_heads': 3e-5,\n",
                "    'warmup_ratio': 0.1,\n",
                "    'patience': 5,\n",
                "    'focal_gamma': 2.0,\n",
                "    'freezing_epochs': 1,\n",
                "    'adversarial_lambda': 0.1,      # How much to punish domain knowledge (Start small)\n",
                "}\n",
                "\n",
                "EMO_COLS = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
                "DATA_DIR = '/kaggle/input/aura-v9-data' \n",
                "print(\"V11 NEMESIS Loaded: Adversarial Protocols Active âš”ï¸\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: GRADIENT REVERSAL LAYER (The Magic)\n",
                "from torch.autograd import Function\n",
                "\n",
                "class GradientReversal(Function):\n",
                "    @staticmethod\n",
                "    def forward(ctx, x, alpha):\n",
                "        ctx.save_for_backward(x, alpha)\n",
                "        return x.view_as(x)\n",
                "\n",
                "    @staticmethod\n",
                "    def backward(ctx, grad_output):\n",
                "        grad_input = None\n",
                "        _, alpha = ctx.saved_tensors\n",
                "        if ctx.needs_input_grad[0]:\n",
                "            # FLIP THE SIGN! (grad * -alpha)\n",
                "            grad_input = - alpha * grad_output\n",
                "        return grad_input, None\n",
                "\n",
                "def grad_reverse(x, alpha=1.0):\n",
                "    return GradientReversal.apply(x, torch.tensor(alpha))\n",
                "\n",
                "print(\"Gradient Reversal Layer defined.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: AURA NEMESIS Model\n",
                "class AURA_CERBERUS(nn.Module):\n",
                "    def __init__(self, config):\n",
                "        super().__init__()\n",
                "        self.bert = BertModel.from_pretrained(config['encoder'])\n",
                "        hidden = self.bert.config.hidden_size\n",
                "        self.dropout = nn.Dropout(config['dropout'])\n",
                "        \n",
                "        # Standard Heads\n",
                "        self.toxicity_head = nn.Linear(hidden, 2)\n",
                "        self.emotion_head = nn.Linear(hidden, config['num_emotion_classes'])\n",
                "        self.sentiment_head = nn.Linear(hidden, 2)\n",
                "        \n",
                "        # ADVERSARY HEAD (Attempts to predict Domain: Tox vs Sent)\n",
                "        self.adversary_head = nn.Linear(hidden, 2)\n",
                "        \n",
                "        # Uncertainty parameters\n",
                "        self.log_var_tox = nn.Parameter(torch.tensor(0.0))\n",
                "        self.log_var_emo = nn.Parameter(torch.tensor(0.0))\n",
                "        self.log_var_sent = nn.Parameter(torch.tensor(0.0))\n",
                "\n",
                "        # COURSE INSIGHT: Bias Initialization (Module 3 - Imbalanced Datasets)\n",
                "        # Initialize Toxicity Head bias to reflect class imbalance (approx 5% toxic)\n",
                "        # log(pos/neg) = log(0.05/0.95) â‰ˆ -2.94\n",
                "        # This prevents the initial \"shock\" and high loss at epoch 0.\n",
                "        with torch.no_grad():\n",
                "             self.toxicity_head.bias[0] = 2.94 # Non-Toxic (Majority)\n",
                "             self.toxicity_head.bias[1] = -2.94 # Toxic (Minority)\n",
                "        \n",
                "    def forward(self, input_ids, attention_mask, alpha=1.0):\n",
                "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
                "        pooled = self.dropout(outputs.pooler_output)\n",
                "        \n",
                "        # 1. Standard Tasks (Normal Gradient)\n",
                "        tox_out = self.toxicity_head(pooled)\n",
                "        emo_out = self.emotion_head(pooled)\n",
                "        sent_out = self.sentiment_head(pooled)\n",
                "        \n",
                "        # 2. Adversarial Task (Reversed Gradient)\n",
                "        # We trick the encoder by reversing the gradient from this head\n",
                "        adv_pooled = grad_reverse(pooled, alpha)\n",
                "        domain_out = self.adversary_head(adv_pooled)\n",
                "        \n",
                "        return {\n",
                "            'toxicity': tox_out,\n",
                "            'emotion': emo_out,\n",
                "            'sentiment': sent_out,\n",
                "            'domain': domain_out,\n",
                "            'log_var_tox': self.log_var_tox,\n",
                "            'log_var_emo': self.log_var_emo,\n",
                "            'log_var_sent': self.log_var_sent\n",
                "        }\n",
                "\n",
                "print('Model AURA NEMESIS defined (with Bias Init).')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: Loss Functions\n",
                "def focal_loss(logits, targets, gamma=2.0, weight=None):\n",
                "    ce = F.cross_entropy(logits, targets, weight=weight, reduction='none')\n",
                "    p_t = torch.exp(-ce)\n",
                "    return ((1 - p_t) ** gamma * ce).mean()\n",
                "\n",
                "def kendall_loss(task_loss, log_var):\n",
                "    log_var = torch.clamp(log_var, min=-5.0, max=5.0)\n",
                "    precision = torch.exp(-log_var)\n",
                "    return precision * task_loss + log_var\n",
                "\n",
                "def compute_mtl_loss(outputs, batch, tox_weights, gamma, adv_lambda):\n",
                "    # A. Primary Tasks Loss (Minimize Error)\n",
                "    task_loss = torch.tensor(0.0, device=outputs['toxicity'].device)\n",
                "    \n",
                "    if batch['task_mask_tox'].sum() > 0:\n",
                "        l = focal_loss(outputs['toxicity'][batch['task_mask_tox']], batch['tox_label'][batch['task_mask_tox']], gamma, tox_weights)\n",
                "        task_loss += kendall_loss(l, outputs['log_var_tox'])\n",
                "        \n",
                "    if batch['task_mask_emo'].sum() > 0:\n",
                "        l = F.binary_cross_entropy_with_logits(outputs['emotion'][batch['task_mask_emo']], batch['emo_label'][batch['task_mask_emo']])\n",
                "        task_loss += kendall_loss(l, outputs['log_var_emo'])\n",
                "        \n",
                "    if batch['task_mask_sent'].sum() > 0:\n",
                "        l = focal_loss(outputs['sentiment'][batch['task_mask_sent']], batch['sent_label'][batch['task_mask_sent']], gamma)\n",
                "        task_loss += kendall_loss(l, outputs['log_var_sent'])\n",
                "        \n",
                "    # B. Adversarial Loss (Minimize Domain Classification Error)\n",
                "    # Wait, didn't we reverse gradient? YES.\n",
                "    # In 'forward', we minimize this loss.\n",
                "    # In 'backward', the gradient flips, so the Encoder effectively Is MAXIMIZING this loss.\n",
                "    \n",
                "    # Only train Adversary on Toxicity vs Sentiment samples (Ignore emotion for simplicity or include all)\n",
                "    # Let's verify we have domain labels.\n",
                "    adv_loss = F.cross_entropy(outputs['domain'], batch['domain_label'])\n",
                "    \n",
                "    # Total = Task + (Lambda * Adversary)\n",
                "    # Note: Lambda scales the gradient reversal strength implicit in the backward pass.\n",
                "    # But usually Lambda is applied here. Wait, grad_reverse ALREADY scales by alpha.\n",
                "    # So we just add the loss.\n",
                "    return task_loss + adv_loss\n",
                "\n",
                "print('Adversarial Loss defined.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: Datasets (Updated with Domain Label)\n",
                "class BaseDataset(Dataset):\n",
                "    def __init__(self, csv_path, tokenizer, max_len):\n",
                "        self.df = pd.read_csv(csv_path)\n",
                "        self.tokenizer = tokenizer\n",
                "        self.max_len = max_len\n",
                "    def __len__(self): return len(self.df)\n",
                "    def encode(self, text):\n",
                "        return self.tokenizer.encode_plus(str(text), max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n",
                "\n",
                "class ToxicityDataset(BaseDataset):\n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        enc = self.encode(row['text'])\n",
                "        return {\n",
                "            'input_ids': enc['input_ids'].flatten(), 'attention_mask': enc['attention_mask'].flatten(),\n",
                "            'tox_label': torch.tensor(int(row['label']), dtype=torch.long), 'emo_label': torch.zeros(len(EMO_COLS)), 'sent_label': torch.tensor(-1, dtype=torch.long),\n",
                "            'task': 'toxicity',\n",
                "            'domain_label': torch.tensor(0, dtype=torch.long) # DOMAIN 0: TOXICITY\n",
                "        }\n",
                "\n",
                "class SentimentDataset(BaseDataset):\n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        enc = self.encode(row['text'])\n",
                "        return {\n",
                "            'input_ids': enc['input_ids'].flatten(), 'attention_mask': enc['attention_mask'].flatten(),\n",
                "            'tox_label': torch.tensor(-1, dtype=torch.long), 'emo_label': torch.zeros(len(EMO_COLS)), 'sent_label': torch.tensor(int(row['label']), dtype=torch.long),\n",
                "            'task': 'sentiment',\n",
                "            'domain_label': torch.tensor(1, dtype=torch.long) # DOMAIN 1: SENTIMENT\n",
                "        }\n",
                "\n",
                "class EmotionDataset(BaseDataset):\n",
                "    def __init__(self, csv_path, tokenizer, max_len, emo_cols):\n",
                "        super().__init__(csv_path, tokenizer, max_len)\n",
                "        self.emo_cols = emo_cols\n",
                "        if 'label_sum' in self.df.columns: self.df = self.df[self.df['label_sum'] > 0].reset_index(drop=True)\n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        enc = self.encode(row['text'])\n",
                "        return {\n",
                "            'input_ids': enc['input_ids'].flatten(), 'attention_mask': enc['attention_mask'].flatten(),\n",
                "            'tox_label': torch.tensor(-1, dtype=torch.long), 'emo_label': torch.tensor([float(row[c]) for c in self.emo_cols]), 'sent_label': torch.tensor(-1, dtype=torch.long),\n",
                "            'task': 'emotion',\n",
                "            'domain_label': torch.tensor(0, dtype=torch.long) # Treat Emotions as 'Toxicity-like' or distinct? Let's assume Domain 0 for simplicity (Source A) or random.\n",
                "            # SCIENTIFIC DECISION: Emotion data is 'neutral ground'. Let's give it Domain 0 to force it to align with Toxicity context, or 0/1 mix.\n",
                "            # SAFEST: Ignore Emotion in Adversary (Mask it out) OR treat as Domain 0.\n",
                "            # Let's set it to 0 so the model learns to align Emotion features with Toxicity features.\n",
                "        }\n",
                "\n",
                "def collate_fn(batch):\n",
                "    tasks = [x['task'] for x in batch]\n",
                "    return {\n",
                "        'input_ids': torch.stack([x['input_ids'] for x in batch]),\n",
                "        'attention_mask': torch.stack([x['attention_mask'] for x in batch]),\n",
                "        'tox_label': torch.stack([x['tox_label'] for x in batch]),\n",
                "        'emo_label': torch.stack([x['emo_label'] for x in batch]),\n",
                "        'sent_label': torch.stack([x['sent_label'] for x in batch]),\n",
                "        'domain_label': torch.stack([x['domain_label'] for x in batch]),\n",
                "        'task_mask_tox': torch.tensor([t == 'toxicity' for t in tasks], dtype=torch.bool), \n",
                "        'task_mask_emo': torch.tensor([t == 'emotion' for t in tasks], dtype=torch.bool),\n",
                "        'task_mask_sent': torch.tensor([t == 'sentiment' for t in tasks], dtype=torch.bool)\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: Loaders\n",
                "tokenizer = BertTokenizer.from_pretrained(CONFIG['encoder'])\n",
                "tox_train = ToxicityDataset(f'{DATA_DIR}/toxicity_train.csv', tokenizer, CONFIG['max_length'])\n",
                "emo_train = EmotionDataset(f'{DATA_DIR}/emotions_train.csv', tokenizer, CONFIG['max_length'], EMO_COLS)\n",
                "sent_train = SentimentDataset(f'{DATA_DIR}/sentiment_train.csv', tokenizer, CONFIG['max_length'])\n",
                "tox_val = ToxicityDataset(f'{DATA_DIR}/toxicity_val.csv', tokenizer, CONFIG['max_length'])\n",
                "\n",
                "train_set = ConcatDataset([tox_train, emo_train, sent_train])\n",
                "train_loader = DataLoader(train_set, batch_size=CONFIG['batch_size'], shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
                "val_loader = DataLoader(tox_val, batch_size=CONFIG['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
                "tox_weights = torch.tensor([0.75, 1.5], device=device)\n",
                "print(\"Datasets loaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 8: Training Engine with FREEZING & ADVERSARIAL Alpha\n",
                "\n",
                "def train_epoch(model, loader, optimizer, scheduler, config, tox_weights, epoch):\n",
                "    model.train()\n",
                "    \n",
                "    if epoch <= config['freezing_epochs']:\n",
                "        print(f\"â„ï¸ EPOCH {epoch}: ICE AGE. Backbone Frozen.\")\n",
                "        for param in model.bert.parameters(): param.requires_grad = False\n",
                "    else:\n",
                "        print(f\"ðŸ”¥ EPOCH {epoch}: FIRE. Backbone Unfrozen.\")\n",
                "        for param in model.bert.parameters(): param.requires_grad = True\n",
                "            \n",
                "    total_loss = 0\n",
                "    optimizer.zero_grad()\n",
                "    pbar = tqdm(loader, desc='Training')\n",
                "    \n",
                "    # DYNAMIC GRL ALPHA: Schedule alpha from 0.0 to 1.0 over epochs to avoid destroying learning early\n",
                "    # This is standard practice in Domain Adaptation.\n",
                "    len_loader = len(loader)\n",
                "    \n",
                "    for step, batch in enumerate(pbar):\n",
                "        # Calculate dynamic alpha (p = progress from 0 to 1)\n",
                "        # p = float(step + (epoch - 1) * len_loader) / (config['epochs'] * len_loader)\n",
                "        # alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
                "        # SIMPLIFIED: Just use fixed lambda for now, pass alpha=1 to layer and scale loss by lambda.\n",
                "        alpha = 1.0\n",
                "\n",
                "        for k, v in batch.items(): \n",
                "            if isinstance(v, torch.Tensor): batch[k] = v.to(device)\n",
                "            \n",
                "        outputs = model(batch['input_ids'], batch['attention_mask'], alpha=alpha)\n",
                "        loss = compute_mtl_loss(outputs, batch, tox_weights, config['focal_gamma'], config['adversarial_lambda'])\n",
                "        \n",
                "        (loss / config['gradient_accumulation']).backward()\n",
                "        \n",
                "        if (step + 1) % config['gradient_accumulation'] == 0:\n",
                "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "            optimizer.step()\n",
                "            scheduler.step()\n",
                "            optimizer.zero_grad()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        if step % 50 == 0:\n",
                "            Ïƒ_t = torch.exp(0.5 * model.log_var_tox).item()\n",
                "            pbar.set_postfix({'loss': loss.item(), 'Ïƒ_tox': f'{Ïƒ_t:.2f}'})\n",
                "            \n",
                "    return total_loss / len(loader)\n",
                "\n",
                "@torch.no_grad()\n",
                "def validate(model, loader):\n",
                "    model.eval()\n",
                "    preds, labels = [], []\n",
                "    for batch in tqdm(loader, desc='Validating', leave=False):\n",
                "        ids, mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
                "        # Alpha 0 in validation (no adversarial effect needed for inference)\n",
                "        out = model(ids, mask, alpha=0.0)\n",
                "        preds.extend(out['toxicity'].argmax(1).cpu().numpy())\n",
                "        labels.extend(batch['tox_label'].to(device).cpu().numpy())\n",
                "    return f1_score(labels, preds, average='macro')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 9: Main Loop V11\n",
                "model = AURA_CERBERUS(CONFIG).to(device)\n",
                "optimizer = torch.optim.AdamW([\n",
                "    {'params': model.bert.parameters(), 'lr': CONFIG['lr_bert']},\n",
                "    {'params': model.toxicity_head.parameters(), 'lr': CONFIG['lr_heads']},\n",
                "    {'params': model.emotion_head.parameters(), 'lr': CONFIG['lr_heads']},\n",
                "    {'params': model.sentiment_head.parameters(), 'lr': CONFIG['lr_heads']},\n",
                "    {'params': model.adversary_head.parameters(), 'lr': CONFIG['lr_heads']}, # NEW\n",
                "    {'params': [model.log_var_tox, model.log_var_emo, model.log_var_sent], 'lr': CONFIG['lr_heads']}\n",
                "], weight_decay=CONFIG['weight_decay'])\n",
                "\n",
                "total_steps = len(train_loader) * CONFIG['epochs'] // CONFIG['gradient_accumulation']\n",
                "scheduler = OneCycleLR(optimizer, max_lr=[CONFIG['lr_bert']] + [CONFIG['lr_heads']]*5, total_steps=total_steps, pct_start=CONFIG['warmup_ratio'])\n",
                "\n",
                "best_val_f1 = 0.0\n",
                "for epoch in range(1, CONFIG['epochs'] + 1):\n",
                "    avg_loss = train_epoch(model, train_loader, optimizer, scheduler, CONFIG, tox_weights, epoch)\n",
                "    val_f1 = validate(model, val_loader)\n",
                "    print(f'Epoch {epoch}: Loss={avg_loss:.4f}, Val F1={val_f1:.4f}')\n",
                "    if val_f1 > best_val_f1:\n",
                "        best_val_f1 = val_f1\n",
                "        torch.save(model.state_dict(), 'aura_v11_nemesis.pt')\n",
                "        print('>>> NEW BEST MODEL <<<')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}