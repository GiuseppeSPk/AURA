{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e241e31d",
   "metadata": {},
   "source": [
    "# üß™ AURA BASELINE - Simplified Version\n",
    "\n",
    "## Professor's Experiment\n",
    "Testing if RoBERTa can disentangle tasks without explicit architecture.\n",
    "\n",
    "**Baseline**: Fine-tune on all datasets concatenated ‚Üí Single toxicity classifier  \n",
    "**AURA V10**: Task-Specific MHA + Kendall Loss ‚Üí F1 = 0.7536\n",
    "\n",
    "**Goal**: Prove Task-Specific architecture adds measurable value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, RobertaModel, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'üîß Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41375698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'encoder': 'roberta-base',\n",
    "    'max_length': 128,\n",
    "    'dropout': 0.3,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 15,\n",
    "    'lr': 2e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'focal_gamma': 2.0,\n",
    "    'label_smoothing': 0.1,\n",
    "    'patience': 5\n",
    "}\n",
    "\n",
    "DATA_DIR = './aura-v10-data'\n",
    "print('üìã Baseline Configuration:')\n",
    "for k, v in CONFIG.items():\n",
    "    print(f'   {k}: {v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Dataset (uses unified CSV)\n",
    "class BaselineDataset(Dataset):\n",
    "    def __init__(self, csv_path, tokenizer, max_len):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        enc = self.tok(\n",
    "            str(row['text']),\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'ids': enc['input_ids'].flatten(),\n",
    "            'mask': enc['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(int(row['label']), dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print('üì¶ Baseline dataset class defined.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model: RoBERTa ‚Üí Linear\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(config['encoder'])\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "        self.classifier = nn.Linear(768, 2)\n",
    "        \n",
    "        # Bias init for imbalanced data\n",
    "        with torch.no_grad():\n",
    "            self.classifier.bias[0] = 2.5\n",
    "            self.classifier.bias[1] = -2.5\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids, attention_mask)\n",
    "        cls = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.classifier(self.dropout(cls))\n",
    "\n",
    "print('ü¶Ö Baseline model defined.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss\n",
    "def focal_loss(logits, targets, gamma=2.0, weight=None, smoothing=0.0):\n",
    "    ce = F.cross_entropy(logits, targets, weight=weight, \n",
    "                         reduction='none', label_smoothing=smoothing)\n",
    "    pt = torch.exp(-ce)\n",
    "    return ((1 - pt) ** gamma * ce).mean()\n",
    "\n",
    "print('‚öñÔ∏è Focal loss defined.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b54a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "tokenizer = RobertaTokenizer.from_pretrained(CONFIG['encoder'])\n",
    "\n",
    "# Load UNIFIED dataset (simplified!)\n",
    "train_ds = BaselineDataset(f'{DATA_DIR}/unified_baseline_train.csv', \n",
    "                           tokenizer, CONFIG['max_length'])\n",
    "val_ds = BaselineDataset(f'{DATA_DIR}/toxicity_val.csv',\n",
    "                         tokenizer, CONFIG['max_length'])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], \n",
    "                          shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'])\n",
    "\n",
    "print('üìä Dataset loaded:')\n",
    "print(f'   Train: {len(train_ds):,} samples (unified)')\n",
    "print(f'   Val:   {len(val_ds):,} samples (toxicity)')\n",
    "print(f'   Batches/epoch: {len(train_loader):,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f13293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup\n",
    "model = BaselineModel(CONFIG).to(device)\n",
    "tox_weights = torch.tensor([0.5, 2.0], device=device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr=CONFIG['lr'], \n",
    "                              weight_decay=CONFIG['weight_decay'])\n",
    "\n",
    "total_steps = len(train_loader) * CONFIG['epochs']\n",
    "warmup_steps = int(total_steps * CONFIG['warmup_ratio'])\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "\n",
    "print(f'Total parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "print(f'Training steps: {total_steps:,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Functions\n",
    "def train_epoch(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}', mininterval=10.0)\n",
    "    \n",
    "    for batch in pbar:\n",
    "        ids = batch['ids'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        logits = model(ids, mask)\n",
    "        loss = focal_loss(logits, labels, \n",
    "                         gamma=CONFIG['focal_gamma'], \n",
    "                         weight=tox_weights, \n",
    "                         smoothing=CONFIG['label_smoothing'])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), CONFIG['max_grad_norm'])\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if len(pbar) % 50 == 0:\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.3f}'})\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    for batch in val_loader:\n",
    "        logits = model(batch['ids'].to(device), batch['mask'].to(device))\n",
    "        preds.extend(logits.argmax(1).cpu().numpy())\n",
    "        trues.extend(batch['label'].numpy())\n",
    "    return f1_score(trues, preds, average='macro', zero_division=0)\n",
    "\n",
    "print('üéØ Training functions ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d87564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "print('='*60)\n",
    "print('üöÄ BASELINE TRAINING START')\n",
    "print('='*60)\n",
    "\n",
    "best_f1 = 0\n",
    "patience_counter = 0\n",
    "history = {'train_loss': [], 'val_f1': []}\n",
    "\n",
    "for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "    train_loss = train_epoch(epoch)\n",
    "    val_f1 = evaluate()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    print(f'\\nEpoch {epoch} Summary:')\n",
    "    print(f'  Train Loss: {train_loss:.4f}')\n",
    "    print(f'  Val F1:     {val_f1:.4f}')\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'baseline_best.pt')\n",
    "        print('  >>> BEST MODEL SAVED <<<')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'  (No improvement. Patience: {patience_counter}/{CONFIG[\"patience\"]})')\n",
    "        \n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f'\\n‚ö†Ô∏è Early stopping at epoch {epoch}')\n",
    "            break\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print(f'‚úÖ Training Complete. Best Val F1: {best_f1:.4f}')\n",
    "print('='*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10acaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Evaluation\n",
    "model.load_state_dict(torch.load('baseline_best.pt'))\n",
    "model.eval()\n",
    "\n",
    "preds, trues = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        logits = model(batch['ids'].to(device), batch['mask'].to(device))\n",
    "        preds.extend(logits.argmax(1).cpu().numpy())\n",
    "        trues.extend(batch['label'].numpy())\n",
    "\n",
    "print('--- Baseline Classification Report ---')\n",
    "print(classification_report(trues, preds, target_names=['Non-Toxic', 'Toxic']))\n",
    "\n",
    "# Comparison\n",
    "print('\\n' + '='*60)\n",
    "print('üìä BASELINE vs AURA V10')\n",
    "print('='*60)\n",
    "baseline_f1 = best_f1\n",
    "aura_f1 = 0.7536\n",
    "\n",
    "print(f'Baseline F1:  {baseline_f1:.4f}')\n",
    "print(f'AURA V10 F1:  {aura_f1:.4f}')\n",
    "print(f'Difference:   {((aura_f1 - baseline_f1) / baseline_f1 * 100):+.2f}%')\n",
    "print('='*60)\n",
    "\n",
    "if aura_f1 > baseline_f1:\n",
    "    gain = ((aura_f1 - baseline_f1) / baseline_f1 * 100)\n",
    "    print(f'\\n‚úÖ RESULT: Task-Specific MHA provides {gain:.1f}% improvement!')\n",
    "    print('   Architecture is JUSTIFIED for the thesis.')\n",
    "else:\n",
    "    print('\\n‚ö†Ô∏è Baseline matches or exceeds AURA V10.')\n",
    "    print('   May need to reconsider architectural complexity.')\n",
    "\n",
    "# Save history\n",
    "import json\n",
    "with open('baseline_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print('\\nüìÅ History saved to baseline_history.json')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
