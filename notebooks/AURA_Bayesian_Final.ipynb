{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üèõÔ∏è AURA: Bayesian Multi-Task Learning (Final Production)\n",
                "\n",
                "---\n",
                "## ‚ö†Ô∏è PRIMA DI ESEGUIRE:\n",
                "1. **Settings** (‚öôÔ∏è) ‚Üí **Accelerator** ‚Üí **GPU T4 x2**\n",
                "2. **Add Input** ‚Üí Carica `aura-data` (deve contenere `goemotions_processed.csv`, `olid_train.csv`, `olid_validation.csv`)\n",
                "---\n",
                "\n",
                "### üî¨ Scientific Specifications\n",
                "- **Architecture**: BERT-Base (Shared Encoder) + Task-Specific Heads\n",
                "- **Uncertainty**: Homoscedastic (Task-Level) Variance Parameters [Kendall 2018]\n",
                "- **Loss Function**: Monte Carlo Sampled NLL + Regularization\n",
                "- **Optimizer**: AdamW + OneCycleLR"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
                "from torch.optim.lr_scheduler import OneCycleLR\n",
                "from transformers import BertModel, BertTokenizer\n",
                "from tqdm.notebook import tqdm\n",
                "from sklearn.metrics import f1_score, classification_report\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"=\"*50)\n",
                "if torch.cuda.is_available():\n",
                "    device = torch.device('cuda')\n",
                "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    device = torch.device('cpu')\n",
                "    print(\"‚ùå NO GPU! Vai su Settings ‚Üí Accelerator ‚Üí GPU T4\")\n",
                "    raise RuntimeError(\"Attiva la GPU prima di procedere!\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "torch.manual_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG = {\n",
                "    'encoder': 'bert-base-uncased',\n",
                "    'max_length': 128,\n",
                "    'num_emotion_classes': 7,\n",
                "    'dropout': 0.1,\n",
                "    'batch_size': 16,\n",
                "    'gradient_accumulation': 2,\n",
                "    'epochs': 5,\n",
                "    'lr': 2e-5,\n",
                "    'weight_decay': 0.01,\n",
                "    'patience': 2,\n",
                "    'mc_samples': 10,  # T=10 Monte Carlo Samples\n",
                "    'output_dir': '/kaggle/working'\n",
                "}\n",
                "\n",
                "# Auto-detect data directory\n",
                "DATA_DIR = None\n",
                "for path in ['/kaggle/input/aura-data', '/kaggle/input/aura-data/kaggle_upload', 'data/processed']:\n",
                "    if os.path.exists(path) and 'olid_train.csv' in os.listdir(path):\n",
                "        DATA_DIR = path\n",
                "        break\n",
                "\n",
                "if DATA_DIR is None:\n",
                "    raise FileNotFoundError(\"Dataset non trovato! Assicurati di aver collegato 'aura-data'.\")\n",
                "\n",
                "print(f\"‚úÖ Dataset trovato: {DATA_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Model Architecture: AURA Bayesian\n",
                "\n",
                "Implements **Homoscedastic Uncertainty** via learnable `log_var` parameters (one per task)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AURA_Bayesian(nn.Module):\n",
                "    \"\"\"\n",
                "    AURA Multi-Task Model with Bayesian Uncertainty.\n",
                "    - Shared BERT Encoder\n",
                "    - Toxicity Head (2 classes)\n",
                "    - Emotion Head (7 classes, multi-label via BCE)\n",
                "    - Task-Level Log Variance (Homoscedastic Uncertainty)\n",
                "    \"\"\"\n",
                "    def __init__(self, config):\n",
                "        super().__init__()\n",
                "        self.bert = BertModel.from_pretrained(config['encoder'])\n",
                "        hidden_size = self.bert.config.hidden_size  # 768\n",
                "        self.dropout = nn.Dropout(config['dropout'])\n",
                "        \n",
                "        # Task Heads\n",
                "        self.toxicity_head = nn.Linear(hidden_size, 2)\n",
                "        self.emotion_head = nn.Linear(hidden_size, config['num_emotion_classes'])\n",
                "        \n",
                "        # Homoscedastic Uncertainty Parameters (Kendall 2018)\n",
                "        # Initialized to 0 => sigma = exp(0/2) = 1\n",
                "        self.tox_log_var = nn.Parameter(torch.zeros(1))\n",
                "        self.emo_log_var = nn.Parameter(torch.zeros(1))\n",
                "        \n",
                "    def forward(self, input_ids, attention_mask):\n",
                "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
                "        pooled = self.dropout(outputs.pooler_output)\n",
                "        \n",
                "        tox_logits = self.toxicity_head(pooled)\n",
                "        emo_logits = self.emotion_head(pooled)\n",
                "        \n",
                "        return tox_logits, emo_logits, self.tox_log_var, self.emo_log_var"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Loss Functions\n",
                "\n",
                "### Monte Carlo Uncertainty Loss (Kendall et al. 2018, Eq. 12)\n",
                "For classification, we sample T corrupted logits, average the softmax probabilities, then compute NLL."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def monte_carlo_uncertainty_loss_classification(logits, log_var, targets, T=10):\n",
                "    \"\"\"\n",
                "    Computes Bayesian Uncertainty Loss for Classification via Monte Carlo Sampling.\n",
                "    \n",
                "    Args:\n",
                "        logits: [B, C] - Raw model predictions\n",
                "        log_var: [1] - Task-level log variance (homoscedastic)\n",
                "        targets: [B] - Ground truth class indices\n",
                "        T: int - Number of Monte Carlo samples\n",
                "    \n",
                "    Returns:\n",
                "        loss: scalar - MC NLL + Regularization\n",
                "    \"\"\"\n",
                "    # 1. Clamp for numerical stability\n",
                "    log_var_clamped = torch.clamp(log_var, min=-10, max=10)\n",
                "    std = torch.exp(0.5 * log_var_clamped)  # sigma = sqrt(exp(log_var))\n",
                "    \n",
                "    # 2. Monte Carlo Sampling: [T, B, C]\n",
                "    logits_expanded = logits.unsqueeze(0).expand(T, -1, -1)\n",
                "    noise = torch.randn_like(logits_expanded)\n",
                "    corrupted_logits = logits_expanded + (noise * std)\n",
                "    \n",
                "    # 3. Softmax & Average across T samples\n",
                "    probs = F.softmax(corrupted_logits, dim=-1)  # [T, B, C]\n",
                "    avg_probs = torch.mean(probs, dim=0)  # [B, C]\n",
                "    \n",
                "    # 4. NLL Loss (with epsilon for stability)\n",
                "    log_probs = torch.log(avg_probs + 1e-8)\n",
                "    nll = F.nll_loss(log_probs, targets)\n",
                "    \n",
                "    # 5. Regularization (penalizes high uncertainty)\n",
                "    regularization = 0.5 * log_var_clamped\n",
                "    \n",
                "    return nll + regularization\n",
                "\n",
                "\n",
                "def monte_carlo_uncertainty_loss_multilabel(logits, log_var, targets, T=10):\n",
                "    \"\"\"\n",
                "    Computes Bayesian Uncertainty Loss for Multi-Label Classification (Emotions).\n",
                "    Uses BCE instead of NLL.\n",
                "    \n",
                "    Args:\n",
                "        logits: [B, C] - Raw model predictions\n",
                "        log_var: [1] - Task-level log variance\n",
                "        targets: [B, C] - Multi-label targets (0 or 1)\n",
                "        T: int - Number of Monte Carlo samples\n",
                "    \n",
                "    Returns:\n",
                "        loss: scalar - MC BCE + Regularization\n",
                "    \"\"\"\n",
                "    log_var_clamped = torch.clamp(log_var, min=-10, max=10)\n",
                "    std = torch.exp(0.5 * log_var_clamped)\n",
                "    \n",
                "    # Monte Carlo Sampling\n",
                "    logits_expanded = logits.unsqueeze(0).expand(T, -1, -1)\n",
                "    noise = torch.randn_like(logits_expanded)\n",
                "    corrupted_logits = logits_expanded + (noise * std)\n",
                "    \n",
                "    # Sigmoid & Average\n",
                "    probs = torch.sigmoid(corrupted_logits)\n",
                "    avg_probs = torch.mean(probs, dim=0)\n",
                "    \n",
                "    # BCE Loss\n",
                "    bce = F.binary_cross_entropy(avg_probs, targets, reduction='mean')\n",
                "    \n",
                "    # Regularization\n",
                "    regularization = 0.5 * log_var_clamped\n",
                "    \n",
                "    return bce + regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Dataset Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AURADataset(Dataset):\n",
                "    \"\"\"\n",
                "    Unified Dataset for both Toxicity (OLID) and Emotion (GoEmotions) tasks.\n",
                "    Uses masking: if is_toxicity=True, emotion labels are -1 (masked).\n",
                "    \"\"\"\n",
                "    def __init__(self, csv_path, tokenizer, max_length, is_toxicity=True):\n",
                "        self.df = pd.read_csv(csv_path)\n",
                "        self.tokenizer = tokenizer\n",
                "        self.max_length = max_length\n",
                "        self.is_toxicity = is_toxicity\n",
                "        self.emo_cols = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.df)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        text = str(row.get('text', row.get('tweet', '')))\n",
                "        \n",
                "        enc = self.tokenizer.encode_plus(\n",
                "            text,\n",
                "            add_special_tokens=True,\n",
                "            max_length=self.max_length,\n",
                "            padding='max_length',\n",
                "            truncation=True,\n",
                "            return_tensors='pt'\n",
                "        )\n",
                "        \n",
                "        # Default: masked labels\n",
                "        tox_label = -1  # Will be ignored in loss\n",
                "        emo_label = torch.full((7,), -1.0)  # Will be ignored in loss\n",
                "        \n",
                "        if self.is_toxicity:\n",
                "            label_raw = row['label'] if 'label' in row else row.get('subtask_a', 'NOT')\n",
                "            tox_label = 1 if label_raw in [1, 'OFF'] else 0\n",
                "        else:\n",
                "            emo_label = torch.tensor([float(row[c]) for c in self.emo_cols], dtype=torch.float32)\n",
                "        \n",
                "        return {\n",
                "            'input_ids': enc['input_ids'].flatten(),\n",
                "            'attention_mask': enc['attention_mask'].flatten(),\n",
                "            'toxicity_target': torch.tensor(tox_label, dtype=torch.long),\n",
                "            'emotion_target': emo_label,\n",
                "            'is_toxicity_task': torch.tensor(1 if self.is_toxicity else 0, dtype=torch.long)\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer = BertTokenizer.from_pretrained(CONFIG['encoder'])\n",
                "\n",
                "# Load datasets\n",
                "olid_train = AURADataset(f\"{DATA_DIR}/olid_train.csv\", tokenizer, CONFIG['max_length'], is_toxicity=True)\n",
                "olid_val = AURADataset(f\"{DATA_DIR}/olid_validation.csv\", tokenizer, CONFIG['max_length'], is_toxicity=True)\n",
                "goemo_full = AURADataset(f\"{DATA_DIR}/goemotions_processed.csv\", tokenizer, CONFIG['max_length'], is_toxicity=False)\n",
                "\n",
                "# Sample GoEmotions to balance with OLID\n",
                "goemo_indices = np.random.choice(len(goemo_full), min(30000, len(goemo_full)), replace=False)\n",
                "goemo_subset = torch.utils.data.Subset(goemo_full, goemo_indices)\n",
                "\n",
                "# Combine for training\n",
                "train_set = ConcatDataset([olid_train, goemo_subset])\n",
                "train_loader = DataLoader(train_set, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2, pin_memory=True)\n",
                "val_loader = DataLoader(olid_val, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2, pin_memory=True)\n",
                "\n",
                "print(f\"‚úÖ Training set: {len(train_set)} samples\")\n",
                "print(f\"‚úÖ Validation set: {len(olid_val)} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Training Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, loader, optimizer, scheduler, epoch):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    tox_preds, tox_labels = [], []\n",
                "    \n",
                "    loop = tqdm(loader, desc=f\"Epoch {epoch}\", leave=True)\n",
                "    optimizer.zero_grad()\n",
                "    \n",
                "    for step, batch in enumerate(loop):\n",
                "        input_ids = batch['input_ids'].to(device)\n",
                "        attention_mask = batch['attention_mask'].to(device)\n",
                "        tox_targets = batch['toxicity_target'].to(device)\n",
                "        emo_targets = batch['emotion_target'].to(device)\n",
                "        is_tox_task = batch['is_toxicity_task'].to(device)\n",
                "        \n",
                "        # Forward\n",
                "        tox_logits, emo_logits, tox_log_var, emo_log_var = model(input_ids, attention_mask)\n",
                "        \n",
                "        # Compute losses (masked)\n",
                "        loss = torch.tensor(0.0, device=device)\n",
                "        \n",
                "        # Toxicity Loss (only where is_tox_task == 1)\n",
                "        tox_mask = is_tox_task == 1\n",
                "        if tox_mask.sum() > 0:\n",
                "            tox_loss = monte_carlo_uncertainty_loss_classification(\n",
                "                tox_logits[tox_mask], \n",
                "                tox_log_var, \n",
                "                tox_targets[tox_mask],\n",
                "                T=CONFIG['mc_samples']\n",
                "            )\n",
                "            loss = loss + tox_loss\n",
                "            \n",
                "            # Track predictions\n",
                "            preds = torch.argmax(tox_logits[tox_mask], dim=1).cpu().numpy()\n",
                "            tox_preds.extend(preds)\n",
                "            tox_labels.extend(tox_targets[tox_mask].cpu().numpy())\n",
                "        \n",
                "        # Emotion Loss (only where is_tox_task == 0)\n",
                "        emo_mask = is_tox_task == 0\n",
                "        if emo_mask.sum() > 0:\n",
                "            emo_loss = monte_carlo_uncertainty_loss_multilabel(\n",
                "                emo_logits[emo_mask], \n",
                "                emo_log_var, \n",
                "                emo_targets[emo_mask],\n",
                "                T=CONFIG['mc_samples']\n",
                "            )\n",
                "            loss = loss + emo_loss\n",
                "        \n",
                "        # Gradient Accumulation\n",
                "        loss = loss / CONFIG['gradient_accumulation']\n",
                "        loss.backward()\n",
                "        \n",
                "        if (step + 1) % CONFIG['gradient_accumulation'] == 0:\n",
                "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "            optimizer.step()\n",
                "            scheduler.step()\n",
                "            optimizer.zero_grad()\n",
                "        \n",
                "        total_loss += loss.item() * CONFIG['gradient_accumulation']\n",
                "        \n",
                "        # Update progress bar\n",
                "        sigma_tox = torch.exp(0.5 * tox_log_var).item()\n",
                "        sigma_emo = torch.exp(0.5 * emo_log_var).item()\n",
                "        loop.set_postfix(loss=loss.item(), œÉ_tox=f\"{sigma_tox:.3f}\", œÉ_emo=f\"{sigma_emo:.3f}\")\n",
                "    \n",
                "    # Calculate epoch metrics\n",
                "    avg_loss = total_loss / len(loader)\n",
                "    train_f1 = f1_score(tox_labels, tox_preds, average='macro') if tox_labels else 0\n",
                "    \n",
                "    return avg_loss, train_f1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8Ô∏è‚É£ Validation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@torch.no_grad()\n",
                "def validate(model, loader):\n",
                "    model.eval()\n",
                "    total_loss = 0\n",
                "    all_preds, all_labels = [], []\n",
                "    \n",
                "    for batch in tqdm(loader, desc=\"Validating\", leave=False):\n",
                "        input_ids = batch['input_ids'].to(device)\n",
                "        attention_mask = batch['attention_mask'].to(device)\n",
                "        tox_targets = batch['toxicity_target'].to(device)\n",
                "        \n",
                "        tox_logits, _, tox_log_var, _ = model(input_ids, attention_mask)\n",
                "        \n",
                "        # Validation uses standard CrossEntropy (no MC needed for eval)\n",
                "        loss = F.cross_entropy(tox_logits, tox_targets)\n",
                "        total_loss += loss.item()\n",
                "        \n",
                "        preds = torch.argmax(tox_logits, dim=1).cpu().numpy()\n",
                "        all_preds.extend(preds)\n",
                "        all_labels.extend(tox_targets.cpu().numpy())\n",
                "    \n",
                "    avg_loss = total_loss / len(loader)\n",
                "    val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
                "    \n",
                "    return avg_loss, val_f1, all_preds, all_labels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9Ô∏è‚É£ Main Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Model\n",
                "model = AURA_Bayesian(CONFIG).to(device)\n",
                "print(f\"‚úÖ Model loaded on {device}\")\n",
                "\n",
                "# Optimizer\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
                "\n",
                "# Scheduler\n",
                "total_steps = len(train_loader) * CONFIG['epochs'] // CONFIG['gradient_accumulation']\n",
                "scheduler = OneCycleLR(optimizer, max_lr=CONFIG['lr'], total_steps=total_steps, pct_start=0.1)\n",
                "\n",
                "# Training\n",
                "best_f1 = 0\n",
                "patience_counter = 0\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üöÄ STARTING BAYESIAN TRAINING\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "for epoch in range(1, CONFIG['epochs'] + 1):\n",
                "    print(f\"\\nüìç Epoch {epoch}/{CONFIG['epochs']}\")\n",
                "    \n",
                "    train_loss, train_f1 = train_epoch(model, train_loader, optimizer, scheduler, epoch)\n",
                "    val_loss, val_f1, preds, labels = validate(model, val_loader)\n",
                "    \n",
                "    # Log Sigma values\n",
                "    sigma_tox = torch.exp(0.5 * model.tox_log_var).item()\n",
                "    sigma_emo = torch.exp(0.5 * model.emo_log_var).item()\n",
                "    \n",
                "    print(f\"   Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f}\")\n",
                "    print(f\"   Val Loss:   {val_loss:.4f} | Val F1:   {val_f1:.4f}\")\n",
                "    print(f\"   œÉ_Tox: {sigma_tox:.4f} | œÉ_Emo: {sigma_emo:.4f}\")\n",
                "    \n",
                "    # Save best model\n",
                "    if val_f1 > best_f1:\n",
                "        best_f1 = val_f1\n",
                "        patience_counter = 0\n",
                "        torch.save(model.state_dict(), f\"{CONFIG['output_dir']}/aura_bayesian_best.pt\")\n",
                "        print(f\"   üíæ New best model saved! (F1: {best_f1:.4f})\")\n",
                "    else:\n",
                "        patience_counter += 1\n",
                "        print(f\"   ‚è≥ No improvement ({patience_counter}/{CONFIG['patience']})\")\n",
                "    \n",
                "    # Early stopping\n",
                "    if patience_counter >= CONFIG['patience']:\n",
                "        print(f\"\\nüõë Early stopping triggered at epoch {epoch}\")\n",
                "        break\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(f\"‚úÖ TRAINING COMPLETE | Best Val F1: {best_f1:.4f}\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîü Final Evaluation & Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "model.load_state_dict(torch.load(f\"{CONFIG['output_dir']}/aura_bayesian_best.pt\"))\n",
                "val_loss, val_f1, preds, labels = validate(model, val_loader)\n",
                "\n",
                "print(\"\\nüìä FINAL CLASSIFICATION REPORT (Toxicity Task)\")\n",
                "print(\"=\"*50)\n",
                "print(classification_report(labels, preds, target_names=['NOT', 'OFF']))\n",
                "\n",
                "print(f\"\\nüèÜ Final Macro-F1: {val_f1:.4f}\")\n",
                "print(f\"\\nüì¶ Model saved to: {CONFIG['output_dir']}/aura_bayesian_best.pt\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}