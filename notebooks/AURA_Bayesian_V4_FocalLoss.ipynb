{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AURA V4: BERT + Clean Data + Focal Loss\n",
                "\n",
                "---\n",
                "## PRIMA DI ESEGUIRE:\n",
                "1. **Settings** -> **Accelerator** -> **GPU T4 x2**\n",
                "2. **Add Input** -> Carica `aura-data-v2`\n",
                "---\n",
                "\n",
                "### V4 Features\n",
                "| Component | Implementation |\n",
                "|-----------|----------------|\n",
                "| Backbone | BERT-base |\n",
                "| Data | Clean (7 emotion classes) |\n",
                "| Loss (Toxicity) | **Focal Loss** (\u03b3=2.0) |\n",
                "| Loss (Emotions) | BCE |\n",
                "| MTL Balancing | Kendall Uncertainty |\n",
                "\n",
                "**Theoretical Advantage**: Focal Loss dynamically down-weights easy examples, focusing on hard negatives."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
                "from torch.optim.lr_scheduler import OneCycleLR\n",
                "from transformers import BertModel, BertTokenizer\n",
                "from tqdm.notebook import tqdm\n",
                "from sklearn.metrics import f1_score, classification_report\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"=\"*50)\n",
                "if torch.cuda.is_available():\n",
                "    device = torch.device('cuda')\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    device = torch.device('cpu')\n",
                "    raise RuntimeError(\"ATTIVA LA GPU!\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "torch.manual_seed(42)\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6767e205",
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG = {\n    'encoder': 'bert-base-uncased',\n    'max_length': 128,\n    'num_emotion_classes': 7,\n    'dropout': 0.1,\n    'batch_size': 16,\n    'gradient_accumulation': 2,\n    'epochs': 5,\n    'lr': 2e-5,\n    'weight_decay': 0.01,\n    'patience': 2,\n    'mc_samples': 10,\n    'focal_gamma': 2.0,  # Ablation: Test [1.0, 2.0, 3.0]\n    'output_dir': '/kaggle/working'\n}\n\n# V4: Using Focal Loss instead of Class Weights\n# Focal Loss (gamma=2.0) automatically focuses on hard examples\nprint(f\"V4: Focal Loss enabled (gamma=2.0)\")\n\n# Data paths - NOTA: usa goemotions_clean.csv (dati puliti)\nDATA_DIR = None\nfor path in ['/kaggle/input/aura-data-v2', '/kaggle/input/aura_data_v2', '/kaggle/input/aura-data', 'data/processed', 'data/kaggle_upload_v2']:\n    if os.path.exists(path):\n        # Cerca il file pulito\n        if os.path.exists(os.path.join(path, 'goemotions_clean.csv')):\n            DATA_DIR = path\n            GOEMO_FILE = 'goemotions_clean.csv'\n            break\n        elif os.path.exists(os.path.join(path, 'goemotions_processed.csv')):\n            DATA_DIR = path\n            GOEMO_FILE = 'goemotions_processed.csv'\n            print(\"WARNING: Using old goemotions_processed.csv!\")\n            break\n\nif DATA_DIR is None:\n    raise FileNotFoundError(\"Dataset non trovato!\")\n\nprint(f\"Dataset: {DATA_DIR}\")\nprint(f\"GoEmotions file: {GOEMO_FILE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model: AURA Bayesian (BERT)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AURA_Bayesian(nn.Module):\n",
                "    def __init__(self, config):\n",
                "        super().__init__()\n",
                "        self.bert = BertModel.from_pretrained(config['encoder'])\n",
                "        hidden_size = self.bert.config.hidden_size\n",
                "        self.dropout = nn.Dropout(config['dropout'])\n",
                "        \n",
                "        self.toxicity_head = nn.Linear(hidden_size, 2)\n",
                "        self.emotion_head = nn.Linear(hidden_size, config['num_emotion_classes'])\n",
                "        \n",
                "        # Homoscedastic Uncertainty (Kendall 2018)\n",
                "        self.tox_log_var = nn.Parameter(torch.zeros(1))\n",
                "        self.emo_log_var = nn.Parameter(torch.zeros(1))\n",
                "        \n",
                "    def forward(self, input_ids, attention_mask):\n",
                "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
                "        pooled = self.dropout(outputs.pooler_output)\n",
                "        \n",
                "        tox_logits = self.toxicity_head(pooled)\n",
                "        emo_logits = self.emotion_head(pooled)\n",
                "        \n",
                "        return tox_logits, emo_logits, self.tox_log_var, self.emo_log_var"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Loss Functions (with Focal Loss)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def focal_loss_with_uncertainty(logits, log_var, targets, gamma=2.0, T=10):\n    \"\"\"\n    Focal Loss integrated with Kendall's Uncertainty (Lin et al., 2017 + Kendall et al., 2018).\n    \n    Focal Loss: FL(p_t) = -(1 - p_t)^gamma * log(p_t)\n    where p_t is the probability of the correct class.\n    \n    Args:\n        logits: Model predictions [batch, num_classes]\n        log_var: Log-variance parameter (Kendall)\n        targets: Ground truth labels [batch]\n        gamma: Focal loss focusing parameter (default: 2.0)\n        T: Monte Carlo samples\n    \"\"\"\n    log_var_clamped = torch.clamp(log_var, min=-10, max=10)\n    std = torch.exp(0.5 * log_var_clamped)\n    \n    # Monte Carlo Sampling\n    logits_expanded = logits.unsqueeze(0).expand(T, -1, -1)\n    noise = torch.randn_like(logits_expanded)\n    corrupted_logits = logits_expanded + (noise * std)\n    \n    # Average probabilities\n    probs = F.softmax(corrupted_logits, dim=-1)\n    avg_probs = torch.mean(probs, dim=0)\n    \n    # Get probabilities of correct class (p_t)\n    p_t = avg_probs[range(len(targets)), targets]\n    \n    # Focal Loss formula: -(1 - p_t)^gamma * log(p_t)\n    focal_weight = (1 - p_t) ** gamma\n    ce_loss = -torch.log(p_t + 1e-8)\n    focal_loss = (focal_weight * ce_loss).mean()\n    \n    # Kendall regularization\n    regularization = 0.5 * log_var_clamped\n    \n    return focal_loss + regularization\n\n\ndef monte_carlo_uncertainty_loss_multilabel(logits, log_var, targets, T=10):\n    \"\"\"\n    Bayesian Uncertainty Loss for Multi-Label (Emotions).\n    \"\"\"\n    log_var_clamped = torch.clamp(log_var, min=-10, max=10)\n    std = torch.exp(0.5 * log_var_clamped)\n    \n    logits_expanded = logits.unsqueeze(0).expand(T, -1, -1)\n    noise = torch.randn_like(logits_expanded)\n    corrupted_logits = logits_expanded + (noise * std)\n    \n    probs = torch.sigmoid(corrupted_logits)\n    avg_probs = torch.mean(probs, dim=0)\n    \n    bce = F.binary_cross_entropy(avg_probs, targets, reduction='mean')\n    regularization = 0.5 * log_var_clamped\n    \n    return bce + regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Dataset Class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AURADataset(Dataset):\n",
                "    def __init__(self, csv_path, tokenizer, max_length, is_toxicity=True):\n",
                "        self.df = pd.read_csv(csv_path)\n",
                "        self.tokenizer = tokenizer\n",
                "        self.max_length = max_length\n",
                "        self.is_toxicity = is_toxicity\n",
                "        self.emo_cols = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.df)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        text = str(row.get('text', row.get('tweet', '')))\n",
                "        \n",
                "        enc = self.tokenizer.encode_plus(\n",
                "            text,\n",
                "            add_special_tokens=True,\n",
                "            max_length=self.max_length,\n",
                "            padding='max_length',\n",
                "            truncation=True,\n",
                "            return_tensors='pt'\n",
                "        )\n",
                "        \n",
                "        tox_label = -1\n",
                "        emo_label = torch.full((7,), -1.0)\n",
                "        \n",
                "        if self.is_toxicity:\n",
                "            label_raw = row['label'] if 'label' in row else row.get('subtask_a', 'NOT')\n",
                "            tox_label = 1 if label_raw in [1, 'OFF'] else 0\n",
                "        else:\n",
                "            emo_label = torch.tensor([float(row[c]) for c in self.emo_cols], dtype=torch.float32)\n",
                "        \n",
                "        return {\n",
                "            'input_ids': enc['input_ids'].flatten(),\n",
                "            'attention_mask': enc['attention_mask'].flatten(),\n",
                "            'toxicity_target': torch.tensor(tox_label, dtype=torch.long),\n",
                "            'emotion_target': emo_label,\n",
                "            'is_toxicity_task': torch.tensor(1 if self.is_toxicity else 0, dtype=torch.long)\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer = BertTokenizer.from_pretrained(CONFIG['encoder'])\n",
                "\n",
                "# Load datasets\n",
                "olid_train = AURADataset(f\"{DATA_DIR}/olid_train.csv\", tokenizer, CONFIG['max_length'], is_toxicity=True)\n",
                "olid_val = AURADataset(f\"{DATA_DIR}/olid_validation.csv\", tokenizer, CONFIG['max_length'], is_toxicity=True)\n",
                "goemo_full = AURADataset(f\"{DATA_DIR}/{GOEMO_FILE}\", tokenizer, CONFIG['max_length'], is_toxicity=False)\n",
                "\n",
                "# Verify GoEmotions is the clean version\n",
                "goemo_df = pd.read_csv(f\"{DATA_DIR}/{GOEMO_FILE}\")\n",
                "disgust_count = goemo_df['disgust'].sum() if 'disgust' in goemo_df.columns else 0\n",
                "neutral_count = goemo_df['neutral'].sum() if 'neutral' in goemo_df.columns else 0\n",
                "print(f\"GoEmotions verification:\")\n",
                "print(f\"  Disgust samples: {disgust_count} (should be >0)\")\n",
                "print(f\"  Neutral samples: {neutral_count} (should be >0)\")\n",
                "\n",
                "if disgust_count == 0 or neutral_count == 0:\n",
                "    print(\"  WARNING: Using broken GoEmotions data!\")\n",
                "else:\n",
                "    print(\"  OK: Clean data confirmed!\")\n",
                "\n",
                "# Sample GoEmotions (use all clean data, it's smaller now)\n",
                "goemo_indices = np.random.choice(len(goemo_full), min(40000, len(goemo_full)), replace=False)\n",
                "goemo_subset = torch.utils.data.Subset(goemo_full, goemo_indices)\n",
                "\n",
                "# Combine\n",
                "train_set = ConcatDataset([olid_train, goemo_subset])\n",
                "train_loader = DataLoader(train_set, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2, pin_memory=True)\n",
                "val_loader = DataLoader(olid_val, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2, pin_memory=True)\n",
                "\n",
                "print(f\"\\nDataset sizes:\")\n",
                "print(f\"  Training: {len(train_set)} (OLID: {len(olid_train)}, GoEmo: {len(goemo_subset)})\")\n",
                "print(f\"  Validation: {len(olid_val)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, loader, optimizer, scheduler, epoch, config):\n    model.train()\n    total_loss = 0\n    tox_preds, tox_labels = [], []\n    \n    loop = tqdm(loader, desc=f\"Epoch {epoch}\", leave=True)\n    optimizer.zero_grad()\n    \n    for step, batch in enumerate(loop):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        tox_targets = batch['toxicity_target'].to(device)\n        emo_targets = batch['emotion_target'].to(device)\n        is_tox_task = batch['is_toxicity_task'].to(device)\n        \n        tox_logits, emo_logits, tox_log_var, emo_log_var = model(input_ids, attention_mask)\n        \n        loss = torch.tensor(0.0, device=device)\n        \n        # Toxicity Loss (with class weights)\n        tox_mask = is_tox_task == 1\n        if tox_mask.sum() > 0:\n            tox_loss = focal_loss_with_uncertainty(\n                tox_logits[tox_mask], \n                tox_log_var, \n                tox_targets[tox_mask],\n                gamma=config['focal_gamma'],\n                T=config['mc_samples']\n            )\n            loss = loss + tox_loss\n            \n            preds = torch.argmax(tox_logits[tox_mask], dim=1).cpu().numpy()\n            tox_preds.extend(preds)\n            tox_labels.extend(tox_targets[tox_mask].cpu().numpy())\n        \n        # Emotion Loss\n        emo_mask = is_tox_task == 0\n        if emo_mask.sum() > 0:\n            emo_loss = monte_carlo_uncertainty_loss_multilabel(\n                emo_logits[emo_mask], \n                emo_log_var, \n                emo_targets[emo_mask],\n                T=config['mc_samples']\n            )\n            loss = loss + emo_loss\n        \n        loss = loss / config['gradient_accumulation']\n        loss.backward()\n        \n        if (step + 1) % config['gradient_accumulation'] == 0:\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n        \n        total_loss += loss.item() * config['gradient_accumulation']\n        \n        sigma_tox = torch.exp(0.5 * tox_log_var).item()\n        sigma_emo = torch.exp(0.5 * emo_log_var).item()\n        loop.set_postfix(loss=loss.item(), s_tox=f\"{sigma_tox:.3f}\", s_emo=f\"{sigma_emo:.3f}\")\n    \n    avg_loss = total_loss / len(loader)\n    train_f1 = f1_score(tox_labels, tox_preds, average='macro') if tox_labels else 0\n    \n    return avg_loss, train_f1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Validation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@torch.no_grad()\n",
                "def validate(model, loader):\n",
                "    model.eval()\n",
                "    total_loss = 0\n",
                "    all_preds, all_labels = [], []\n",
                "    \n",
                "    for batch in tqdm(loader, desc=\"Validating\", leave=False):\n",
                "        input_ids = batch['input_ids'].to(device)\n",
                "        attention_mask = batch['attention_mask'].to(device)\n",
                "        tox_targets = batch['toxicity_target'].to(device)\n",
                "        \n",
                "        tox_logits, _, _, _ = model(input_ids, attention_mask)\n",
                "        \n",
                "        loss = F.cross_entropy(tox_logits, tox_targets)\n",
                "        total_loss += loss.item()\n",
                "        \n",
                "        preds = torch.argmax(tox_logits, dim=1).cpu().numpy()\n",
                "        all_preds.extend(preds)\n",
                "        all_labels.extend(tox_targets.cpu().numpy())\n",
                "    \n",
                "    avg_loss = total_loss / len(loader)\n",
                "    val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
                "    \n",
                "    return avg_loss, val_f1, all_preds, all_labels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Main Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = AURA_Bayesian(CONFIG).to(device)\nprint(f\"Model: BERT (110M params) on {device}\")\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n\ntotal_steps = len(train_loader) * CONFIG['epochs'] // CONFIG['gradient_accumulation']\nscheduler = OneCycleLR(optimizer, max_lr=CONFIG['lr'], total_steps=total_steps, pct_start=0.1)\n\nbest_f1 = 0\npatience_counter = 0\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING V4 TRAINING (Clean Data + Focal Loss)\")\nprint(\"=\"*60)\n\nfor epoch in range(1, CONFIG['epochs'] + 1):\n    print(f\"\\nEpoch {epoch}/{CONFIG['epochs']}\")\n    \n    train_loss, train_f1 = train_epoch(model, train_loader, optimizer, scheduler, epoch, CONFIG)\n    val_loss, val_f1, preds, labels = validate(model, val_loader)\n    \n    sigma_tox = torch.exp(0.5 * model.tox_log_var).item()\n    sigma_emo = torch.exp(0.5 * model.emo_log_var).item()\n    gap = abs(train_f1 - val_f1) * 100\n    \n    print(f\"   Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f}\")\n    print(f\"   Val Loss:   {val_loss:.4f} | Val F1:   {val_f1:.4f}\")\n    print(f\"   Gap: {gap:.1f}% | sigma_Tox: {sigma_tox:.4f} | sigma_Emo: {sigma_emo:.4f}\")\n    \n    if val_f1 > best_f1:\n        best_f1 = val_f1\n        patience_counter = 0\n        torch.save(model.state_dict(), f\"{CONFIG['output_dir']}/aura_v4_focal_best.pt\")\n        print(f\"   NEW BEST! (F1: {best_f1:.4f})\")\n    else:\n        patience_counter += 1\n        print(f\"   No improvement ({patience_counter}/{CONFIG['patience']})\")\n    \n    if patience_counter >= CONFIG['patience']:\n        print(f\"\\nEarly stopping at epoch {epoch}\")\n        break\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"TRAINING COMPLETE | Best Val F1: {best_f1:.4f}\")\nprint(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Final Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.load_state_dict(torch.load(f\"{CONFIG['output_dir']}/aura_v4_focal_best.pt\"))\nval_loss, val_f1, preds, labels = validate(model, val_loader)\n\nprint(\"\\nFINAL CLASSIFICATION REPORT (V4 - Clean Data + Focal Loss)\")\nprint(\"=\"*50)\nprint(classification_report(labels, preds, target_names=['NOT', 'OFF']))\n\nprint(f\"\\nFinal Macro-F1: {val_f1:.4f}\")\nprint(f\"Model saved: {CONFIG['output_dir']}/aura_v4_focal_best.pt\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}