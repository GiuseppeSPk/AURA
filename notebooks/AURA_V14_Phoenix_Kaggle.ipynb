{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AURA V14 PHOENIX - Multi-Task Toxicity Detection\n",
    "\n",
    "**Architecture**: RoBERTa + Task-Specific Attention + 4 Classification Heads\n",
    "\n",
    "**Tasks**:\n",
    "1. **Toxicity Detection** (Binary: Toxic/Non-Toxic)\n",
    "2. **Emotion Recognition** (Multi-label: 7 Ekman emotions)\n",
    "3. **Sentiment Analysis** (Binary: Positive/Negative)\n",
    "4. **Reporting Detection** (Binary: Direct/Reported speech)\n",
    "\n",
    "**Key Innovation**: Each task has its own attention layer that learns WHERE to look in the sequence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration V14 (PHOENIX)\n",
    "CONFIG = {\n",
    "    'encoder': 'roberta-base',\n",
    "    'max_length': 128,\n",
    "    'num_emotion_classes': 7,\n",
    "    'dropout': 0.3,\n",
    "    'weight_decay': 0.01,\n",
    "    'batch_size': 16,\n",
    "    'gradient_accumulation': 4,\n",
    "    'epochs': 5,\n",
    "    'lr_encoder': 2e-5,\n",
    "    'lr_heads': 5e-5,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'patience': 3,\n",
    "    'focal_gamma': 2.0,\n",
    "    'label_smoothing': 0.1,\n",
    "    'freezing_epochs': 1,\n",
    "}\n",
    "\n",
    "EMO_COLS = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
    "DATA_DIR = '/kaggle/input/aura-v14-data'\n",
    "print(\"V14 PHOENIX Loaded: RoBERTa + Task-Specific Attention ðŸ”¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Task-Specific Attention Layer\n",
    "class TaskAttention(nn.Module):\n",
    "    \"\"\"Each task learns WHERE to look in the sequence.\"\"\"\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(hidden_size, hidden_size)\n",
    "        self.key = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value = nn.Linear(hidden_size, hidden_size)\n",
    "        self.scale = hidden_size ** 0.5\n",
    "        \n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        # hidden_states: [batch, seq_len, hidden]\n",
    "        # Use [CLS] token (position 0) as query\n",
    "        cls_token = hidden_states[:, 0:1, :]  # [batch, 1, hidden]\n",
    "        \n",
    "        Q = self.query(cls_token)      # [batch, 1, hidden]\n",
    "        K = self.key(hidden_states)    # [batch, seq, hidden]\n",
    "        V = self.value(hidden_states)  # [batch, seq, hidden]\n",
    "        \n",
    "        # Attention scores\n",
    "        scores = torch.bmm(Q, K.transpose(1, 2)) / self.scale  # [batch, 1, seq]\n",
    "        \n",
    "        # Mask padding tokens\n",
    "        if attention_mask is not None:\n",
    "            mask = attention_mask.unsqueeze(1)  # [batch, 1, seq]\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        attn_weights = F.softmax(scores, dim=-1)  # [batch, 1, seq]\n",
    "        \n",
    "        # Weighted sum of values\n",
    "        output = torch.bmm(attn_weights, V)  # [batch, 1, hidden]\n",
    "        return output.squeeze(1), attn_weights.squeeze(1)\n",
    "\n",
    "print('TaskAttention layer defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: AURA PHOENIX Model\n",
    "class AURA_PHOENIX(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(config['encoder'])\n",
    "        hidden = self.roberta.config.hidden_size  # 768 for roberta-base\n",
    "        \n",
    "        # Task-Specific Attention Layers\n",
    "        self.tox_attention = TaskAttention(hidden)\n",
    "        self.emo_attention = TaskAttention(hidden)\n",
    "        self.sent_attention = TaskAttention(hidden)\n",
    "        self.report_attention = TaskAttention(hidden)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "        \n",
    "        # Classification Heads\n",
    "        self.toxicity_head = nn.Linear(hidden, 2)\n",
    "        self.emotion_head = nn.Linear(hidden, config['num_emotion_classes'])\n",
    "        self.sentiment_head = nn.Linear(hidden, 2)\n",
    "        self.reporting_head = nn.Linear(hidden, 1)  # Binary sigmoid\n",
    "        \n",
    "        # Bias Initialization for imbalanced toxicity (~5% toxic)\n",
    "        with torch.no_grad():\n",
    "            self.toxicity_head.bias[0] = 2.5   # Non-Toxic\n",
    "            self.toxicity_head.bias[1] = -2.5  # Toxic\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state  # [batch, seq, hidden]\n",
    "        \n",
    "        # Each task attends to different parts of the sequence\n",
    "        tox_repr, tox_attn = self.tox_attention(hidden_states, attention_mask)\n",
    "        emo_repr, emo_attn = self.emo_attention(hidden_states, attention_mask)\n",
    "        sent_repr, sent_attn = self.sent_attention(hidden_states, attention_mask)\n",
    "        report_repr, report_attn = self.report_attention(hidden_states, attention_mask)\n",
    "        \n",
    "        # Apply dropout\n",
    "        tox_repr = self.dropout(tox_repr)\n",
    "        emo_repr = self.dropout(emo_repr)\n",
    "        sent_repr = self.dropout(sent_repr)\n",
    "        report_repr = self.dropout(report_repr)\n",
    "        \n",
    "        return {\n",
    "            'toxicity': self.toxicity_head(tox_repr),\n",
    "            'emotion': self.emotion_head(emo_repr),\n",
    "            'sentiment': self.sentiment_head(sent_repr),\n",
    "            'reporting': self.reporting_head(report_repr).squeeze(-1),\n",
    "            'attention': {\n",
    "                'tox': tox_attn, 'emo': emo_attn, \n",
    "                'sent': sent_attn, 'report': report_attn\n",
    "            }\n",
    "        }\n",
    "\n",
    "print('AURA PHOENIX model defined (RoBERTa + 4 Task Attention Heads).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Loss Functions\n",
    "def focal_loss(logits, targets, gamma=2.0, weight=None, smoothing=0.0):\n",
    "    \"\"\"Focal Loss with optional Label Smoothing.\"\"\"\n",
    "    ce = F.cross_entropy(logits, targets, weight=weight, reduction='none', label_smoothing=smoothing)\n",
    "    p_t = torch.exp(-ce)\n",
    "    return ((1 - p_t) ** gamma * ce).mean()\n",
    "\n",
    "def compute_loss(outputs, batch, tox_weights, config):\n",
    "    \"\"\"Multi-task loss computation.\"\"\"\n",
    "    total_loss = torch.tensor(0.0, device=outputs['toxicity'].device)\n",
    "    \n",
    "    # 1. Toxicity Loss (Focal + Label Smoothing)\n",
    "    if batch['task_mask_tox'].sum() > 0:\n",
    "        tox_logits = outputs['toxicity'][batch['task_mask_tox']]\n",
    "        tox_labels = batch['tox_label'][batch['task_mask_tox']]\n",
    "        total_loss += focal_loss(tox_logits, tox_labels, \n",
    "                                 gamma=config['focal_gamma'], \n",
    "                                 weight=tox_weights,\n",
    "                                 smoothing=config['label_smoothing'])\n",
    "    \n",
    "    # 2. Emotion Loss (BCE)\n",
    "    if batch['task_mask_emo'].sum() > 0:\n",
    "        emo_logits = outputs['emotion'][batch['task_mask_emo']]\n",
    "        emo_labels = batch['emo_label'][batch['task_mask_emo']]\n",
    "        total_loss += F.binary_cross_entropy_with_logits(emo_logits, emo_labels)\n",
    "    \n",
    "    # 3. Sentiment Loss (Focal)\n",
    "    if batch['task_mask_sent'].sum() > 0:\n",
    "        sent_logits = outputs['sentiment'][batch['task_mask_sent']]\n",
    "        sent_labels = batch['sent_label'][batch['task_mask_sent']]\n",
    "        total_loss += focal_loss(sent_logits, sent_labels, \n",
    "                                 gamma=config['focal_gamma'],\n",
    "                                 smoothing=config['label_smoothing'])\n",
    "    \n",
    "    # 4. Reporting Loss (BCE)\n",
    "    if batch['task_mask_report'].sum() > 0:\n",
    "        report_logits = outputs['reporting'][batch['task_mask_report']]\n",
    "        report_labels = batch['report_label'][batch['task_mask_report']].float()\n",
    "        total_loss += F.binary_cross_entropy_with_logits(report_logits, report_labels)\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "print('Loss functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Dataset Classes\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, csv_path, tokenizer, max_len):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self): return len(self.df)\n",
    "    def encode(self, text):\n",
    "        return self.tokenizer.encode_plus(\n",
    "            str(text), max_length=self.max_len, \n",
    "            padding='max_length', truncation=True, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "class ToxicityDataset(BaseDataset):\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        enc = self.encode(row['text'])\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].flatten(),\n",
    "            'attention_mask': enc['attention_mask'].flatten(),\n",
    "            'tox_label': torch.tensor(int(row['label']), dtype=torch.long),\n",
    "            'emo_label': torch.zeros(7),\n",
    "            'sent_label': torch.tensor(-1, dtype=torch.long),\n",
    "            'report_label': torch.tensor(-1, dtype=torch.long),\n",
    "            'task': 'toxicity'\n",
    "        }\n",
    "\n",
    "class EmotionDataset(BaseDataset):\n",
    "    def __init__(self, csv_path, tokenizer, max_len, emo_cols):\n",
    "        super().__init__(csv_path, tokenizer, max_len)\n",
    "        self.emo_cols = emo_cols\n",
    "        if 'label_sum' in self.df.columns:\n",
    "            self.df = self.df[self.df['label_sum'] > 0].reset_index(drop=True)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        enc = self.encode(row['text'])\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].flatten(),\n",
    "            'attention_mask': enc['attention_mask'].flatten(),\n",
    "            'tox_label': torch.tensor(-1, dtype=torch.long),\n",
    "            'emo_label': torch.tensor([float(row[c]) for c in self.emo_cols]),\n",
    "            'sent_label': torch.tensor(-1, dtype=torch.long),\n",
    "            'report_label': torch.tensor(-1, dtype=torch.long),\n",
    "            'task': 'emotion'\n",
    "        }\n",
    "\n",
    "class SentimentDataset(BaseDataset):\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        enc = self.encode(row['text'])\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].flatten(),\n",
    "            'attention_mask': enc['attention_mask'].flatten(),\n",
    "            'tox_label': torch.tensor(-1, dtype=torch.long),\n",
    "            'emo_label': torch.zeros(7),\n",
    "            'sent_label': torch.tensor(int(row['label']), dtype=torch.long),\n",
    "            'report_label': torch.tensor(-1, dtype=torch.long),\n",
    "            'task': 'sentiment'\n",
    "        }\n",
    "\n",
    "class ReportingDataset(BaseDataset):\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        enc = self.encode(row['text'])\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].flatten(),\n",
    "            'attention_mask': enc['attention_mask'].flatten(),\n",
    "            'tox_label': torch.tensor(-1, dtype=torch.long),\n",
    "            'emo_label': torch.zeros(7),\n",
    "            'sent_label': torch.tensor(-1, dtype=torch.long),\n",
    "            'report_label': torch.tensor(int(row['is_reporting']), dtype=torch.long),\n",
    "            'task': 'reporting'\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tasks = [x['task'] for x in batch]\n",
    "    return {\n",
    "        'input_ids': torch.stack([x['input_ids'] for x in batch]),\n",
    "        'attention_mask': torch.stack([x['attention_mask'] for x in batch]),\n",
    "        'tox_label': torch.stack([x['tox_label'] for x in batch]),\n",
    "        'emo_label': torch.stack([x['emo_label'] for x in batch]),\n",
    "        'sent_label': torch.stack([x['sent_label'] for x in batch]),\n",
    "        'report_label': torch.stack([x['report_label'] for x in batch]),\n",
    "        'task_mask_tox': torch.tensor([t == 'toxicity' for t in tasks], dtype=torch.bool),\n",
    "        'task_mask_emo': torch.tensor([t == 'emotion' for t in tasks], dtype=torch.bool),\n",
    "        'task_mask_sent': torch.tensor([t == 'sentiment' for t in tasks], dtype=torch.bool),\n",
    "        'task_mask_report': torch.tensor([t == 'reporting' for t in tasks], dtype=torch.bool)\n",
    "    }\n",
    "\n",
    "print('Dataset classes defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load Data\n",
    "tokenizer = RobertaTokenizer.from_pretrained(CONFIG['encoder'])\n",
    "\n",
    "tox_train = ToxicityDataset(f'{DATA_DIR}/toxicity_train.csv', tokenizer, CONFIG['max_length'])\n",
    "emo_train = EmotionDataset(f'{DATA_DIR}/emotions_train.csv', tokenizer, CONFIG['max_length'], EMO_COLS)\n",
    "sent_train = SentimentDataset(f'{DATA_DIR}/sentiment_train.csv', tokenizer, CONFIG['max_length'])\n",
    "report_train = ReportingDataset(f'{DATA_DIR}/reporting_examples.csv', tokenizer, CONFIG['max_length'])\n",
    "tox_val = ToxicityDataset(f'{DATA_DIR}/toxicity_val.csv', tokenizer, CONFIG['max_length'])\n",
    "\n",
    "train_set = ConcatDataset([tox_train, emo_train, sent_train, report_train])\n",
    "train_loader = DataLoader(train_set, batch_size=CONFIG['batch_size'], shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
    "val_loader = DataLoader(tox_val, batch_size=CONFIG['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "tox_weights = torch.tensor([0.5, 2.0], device=device)  # Class weights for imbalance\n",
    "\n",
    "print(f'Training samples: {len(train_set)}')\n",
    "print(f'  - Toxicity: {len(tox_train)}')\n",
    "print(f'  - Emotions: {len(emo_train)}')\n",
    "print(f'  - Sentiment: {len(sent_train)}')\n",
    "print(f'  - Reporting: {len(report_train)}')\n",
    "print(f'Validation samples: {len(tox_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Training Functions (Following NB10 patterns)\n",
    "def plot_history(history, metric):\n",
    "    \"\"\"Plot training history (from NB10).\"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history[metric], label='Train')\n",
    "    if f'val_{metric}' in history:\n",
    "        plt.plot(history[f'val_{metric}'], label='Validation')\n",
    "    plt.title(f'Model {metric.capitalize()}')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def train_epoch(model, loader, optimizer, scheduler, config, tox_weights, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    # Progressive Freezing (from V10)\n",
    "    if epoch <= config['freezing_epochs']:\n",
    "        print(f\"â„ï¸ Epoch {epoch}: Encoder FROZEN\")\n",
    "        for param in model.roberta.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(f\"ðŸ”¥ Epoch {epoch}: Encoder UNFROZEN\")\n",
    "        for param in model.roberta.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    pbar = tqdm(loader, desc=f'Epoch {epoch}')\n",
    "    \n",
    "    for step, batch in enumerate(pbar):\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.to(device)\n",
    "        \n",
    "        outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "        loss = compute_loss(outputs, batch, tox_weights, config)\n",
    "        \n",
    "        (loss / config['gradient_accumulation']).backward()\n",
    "        \n",
    "        if (step + 1) % config['gradient_accumulation'] == 0:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    \n",
    "    for batch in tqdm(loader, desc='Validating', leave=False):\n",
    "        ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        out = model(ids, mask)\n",
    "        preds.extend(out['toxicity'].argmax(1).cpu().numpy())\n",
    "        labels.extend(batch['tox_label'].cpu().numpy())\n",
    "    \n",
    "    return f1_score(labels, preds, average='macro')\n",
    "\n",
    "print('Training functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Main Training Loop\n",
    "print(\"=\"*60)\n",
    "print(\"AURA V14 PHOENIX - TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = AURA_PHOENIX(CONFIG).to(device)\n",
    "\n",
    "# Optimizer with different LR for encoder vs heads (from V10)\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.roberta.parameters(), 'lr': CONFIG['lr_encoder']},\n",
    "    {'params': model.tox_attention.parameters(), 'lr': CONFIG['lr_heads']},\n",
    "    {'params': model.emo_attention.parameters(), 'lr': CONFIG['lr_heads']},\n",
    "    {'params': model.sent_attention.parameters(), 'lr': CONFIG['lr_heads']},\n",
    "    {'params': model.report_attention.parameters(), 'lr': CONFIG['lr_heads']},\n",
    "    {'params': model.toxicity_head.parameters(), 'lr': CONFIG['lr_heads']},\n",
    "    {'params': model.emotion_head.parameters(), 'lr': CONFIG['lr_heads']},\n",
    "    {'params': model.sentiment_head.parameters(), 'lr': CONFIG['lr_heads']},\n",
    "    {'params': model.reporting_head.parameters(), 'lr': CONFIG['lr_heads']},\n",
    "], weight_decay=CONFIG['weight_decay'])\n",
    "\n",
    "total_steps = len(train_loader) * CONFIG['epochs'] // CONFIG['gradient_accumulation']\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=[CONFIG['lr_encoder']] + [CONFIG['lr_heads']]*8,\n",
    "    total_steps=total_steps, \n",
    "    pct_start=CONFIG['warmup_ratio']\n",
    ")\n",
    "\n",
    "# Training history (from NB10)\n",
    "history = {'loss': [], 'val_f1': []}\n",
    "best_val_f1 = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "    avg_loss = train_epoch(model, train_loader, optimizer, scheduler, CONFIG, tox_weights, epoch)\n",
    "    val_f1 = validate(model, val_loader)\n",
    "    \n",
    "    history['loss'].append(avg_loss)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    print(f'Epoch {epoch}: Loss={avg_loss:.4f}, Val F1={val_f1:.4f}')\n",
    "    \n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'aura_v14_phoenix.pt')\n",
    "        print('>>> NEW BEST MODEL SAVED <<<')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            break\n",
    "\n",
    "print(f\"\\nTraining Complete. Best Val F1: {best_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Plot Training History\n",
    "plot_history(history, 'loss')\n",
    "plot_history(history, 'val_f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Inference Function with Reporting Adjustment\n",
    "@torch.no_grad()\n",
    "def predict_toxicity(model, tokenizer, text, threshold=0.5):\n",
    "    \"\"\"Predict toxicity with reporting-aware adjustment.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    enc = tokenizer.encode_plus(\n",
    "        text, max_length=128, padding='max_length', \n",
    "        truncation=True, return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    ids = enc['input_ids'].to(device)\n",
    "    mask = enc['attention_mask'].to(device)\n",
    "    \n",
    "    out = model(ids, mask)\n",
    "    \n",
    "    tox_probs = F.softmax(out['toxicity'], dim=1)\n",
    "    tox_score = tox_probs[0, 1].item()  # P(toxic)\n",
    "    \n",
    "    report_score = torch.sigmoid(out['reporting']).item()\n",
    "    \n",
    "    # Adjust toxicity if reporting detected\n",
    "    if report_score > 0.5:\n",
    "        adjusted_tox = tox_score * (1 - report_score * 0.5)  # Reduce confidence\n",
    "    else:\n",
    "        adjusted_tox = tox_score\n",
    "    \n",
    "    is_toxic = adjusted_tox > threshold\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'raw_toxicity': tox_score,\n",
    "        'reporting_score': report_score,\n",
    "        'adjusted_toxicity': adjusted_tox,\n",
    "        'is_toxic': is_toxic\n",
    "    }\n",
    "\n",
    "print('Inference function defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Stress Test\n",
    "print(\"=\"*60)\n",
    "print(\"STRESS TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('aura_v14_phoenix.pt'))\n",
    "model.eval()\n",
    "\n",
    "test_cases = [\n",
    "    # Should be NON-TOXIC (negative but not toxic)\n",
    "    \"I hate rainy Mondays\",\n",
    "    \"This soup is disgusting\",\n",
    "    \"I am so angry at the traffic\",\n",
    "    \"This movie was terrible\",\n",
    "    \n",
    "    # Should be TOXIC\n",
    "    \"You are an idiot\",\n",
    "    \"I hate you so much\",\n",
    "    \"Go kill yourself\",\n",
    "    \"You are worthless garbage\",\n",
    "    \n",
    "    # Should be NON-TOXIC (reporting)\n",
    "    \"He said you are an idiot\",\n",
    "    \"The article discusses hate speech\",\n",
    "    \"Someone wrote 'go die' in the comments\",\n",
    "    \"The report mentions racist slurs\",\n",
    "]\n",
    "\n",
    "print(f\"{'Text':<50} {'Raw':<8} {'Report':<8} {'Adj':<8} {'Toxic?'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for text in test_cases:\n",
    "    result = predict_toxicity(model, tokenizer, text)\n",
    "    print(f\"{text[:48]:<50} {result['raw_toxicity']:.2f}    {result['reporting_score']:.2f}    {result['adjusted_toxicity']:.2f}    {'âŒ TOXIC' if result['is_toxic'] else 'âœ… OK'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
